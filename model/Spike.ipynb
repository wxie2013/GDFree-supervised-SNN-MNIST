{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>:root { --jp-notebook-max-width: 100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these command make the cell width wider than default\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>:root { --jp-notebook-max-width: 100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spike():\n",
    "    def __init__(self, hyperPar):\n",
    "        self.num_classes = input_param.num_classes # number of classies for classification, i.e. 10 for MNIST data\n",
    "        self.switch_norm = info_hyperparams('switch_norm',hyperPar) # normalize weight every run\n",
    "        self.n_syn = info_hyperparams('n_syn',hyperPar) # number of synapses per pre-post pair. now it's a dummy variable.\n",
    "        self.stdp_type = info_hyperparams('stdp_type',hyperPar) # stdp type\n",
    "        self.N_e = [int(math.pow(self.sqrt_grp_size[ih],2)*input_param.num_classes) for ih in range(len(self.sqrt_grp_size))]\n",
    "        self.max_delay_input2e = info_hyperparams('max_delay_input2e', hyperPar, brian2.ms) # max axonic delay\n",
    "        self.max_delay_efe = info_hyperparams('max_delay_efe', hyperPar, brian2.ms) # max axonic delay\n",
    "        self.max_dendritic_delay = info_hyperparams('max_dendritic_delay', hyperPar, brian2.ms) # max dendritic delay\n",
    "        self.tau_adpt = info_hyperparams('tau_adpt', hyperPar, brian2.ms)  # adaptive threshold time constant\n",
    "        self.delta_vt = info_hyperparams('delta_vt', hyperPar, brian2.mV)  # increment for adaptive threshold\n",
    "        self.tau_membrane_exci = info_hyperparams('tau_membrane_exci', hyperPar, brian2.ms)\n",
    "        self.tau_ge = info_hyperparams('tau_ge', hyperPar, brian2.ms)\n",
    "        self.tau_gi = info_hyperparams('tau_gi', hyperPar, brian2.ms) \n",
    "        self.sigma_noise = info_hyperparams('sigma_noise', hyperPar, brian2.mV) #  sigma for Ornstein-Unlenbeck noise\n",
    "        self.gmax_input2e = info_hyperparams('gmax_input2e', hyperPar)  # for syn between input and hidden layers\n",
    "        self.gmax_efe = info_hyperparams('gmax_efe', hyperPar)  # for syn between different hidden layers in forward direction\n",
    "        self.norm_scale_S_input2e = info_hyperparams('norm_scale_S_input2e', hyperPar) # average weight for S_input2e\n",
    "        self.norm_scale_S_efe = info_hyperparams('norm_scale_S_efe', hyperPar) # average weight for S_efe\n",
    "        self.penalty_input2e = info_hyperparams('penalty_input2e', hyperPar)\n",
    "        self.penalty_efe = info_hyperparams('penalty_efe', hyperPar)\n",
    "        self.dW_e2e = info_hyperparams('dW_e2e', hyperPar)\n",
    "        self.w_sat_scale = info_hyperparams('w_sat_scale', hyperPar) # range->[0,1], determine how fast the weight saturate\n",
    "        self.w_sat_shift = info_hyperparams('w_sat_shift', hyperPar) # range->[0,1], shift the drop-own part of the tanh function to higher or lower value \n",
    "        self.vt_sat_scale = info_hyperparams('vt_sat_scale', hyperPar) # range->[0,1], same function as w_sat_scale but for determining how fast the vt saturate\n",
    "        self.vt_sat_shift = info_hyperparams('vt_sat_shift', hyperPar) # range->[0,1], shift the drop-own part of the tanh function to higher or lower value \n",
    "                                             \n",
    "        # neuron parameters \n",
    "        self.v_thres_exci = info_hyperparams('v_thres_exci', hyperPar, brian2.mV) \n",
    "        self.v_reversal_e_exci = info_hyperparams('v_reversal_e_exci', hyperPar, brian2.mV)\n",
    "        self.v_reversal_i_exci = info_hyperparams('v_reversal_i_exci', hyperPar, brian2.mV)\n",
    "        self.v_rest_exci = info_hyperparams('v_rest_exci', hyperPar, brian2.mV)\n",
    "        self.v_reset_exci = info_hyperparams('v_reset_exci', hyperPar, brian2.mV)\n",
    "        self.refrac_time_exci = info_hyperparams('refrac_time_exci', hyperPar, brian2.ms)\n",
    "\n",
    "        # network to collect all information before run\n",
    "        self.col = brian2.Network()\n",
    "        \n",
    "        #\n",
    "        if self.debug == True:\n",
    "            print('self.switch_norm: ', self.switch_norm)\n",
    "            print('self.N_hidden: ', self.N_hidden)\n",
    "            print('self.N_e: ', self.N_e)\n",
    "            print('self.max_delay_input2e: ', self.max_delay_input2e)\n",
    "            print('self.max_delay_efe: ', self.max_delay_efe)\n",
    "            print('self.n_syn: ', self.n_syn)\n",
    "            print('self.tau_adpt: ', self.tau_adpt)\n",
    "            print('self.delta_vt: ', self.delta_vt)\n",
    "            print('self.vt_sat_scale: ', self.vt_sat_scale)\n",
    "            print('self.vt_sat_shift: ', self.vt_sat_shift)\n",
    "            print('self.tau_membrane_exci: ', self.tau_membrane_exci)\n",
    "            print('self.tau_ge: ', self.tau_ge)\n",
    "            print('self.tau_gi: ', self.tau_gi)\n",
    "            print('self.sigma_noise: ', self.sigma_noise)\n",
    "            print('self.gmax_input2e: ', self.gmax_input2e)\n",
    "            print('self.gmax_efe: ', self.gmax_efe)\n",
    "            print('self.norm_scale_S_input2e: ', self.norm_scale_S_input2e)\n",
    "            print('self.norm_scale_S_efe: ', self.norm_scale_S_efe)\n",
    "            print('self.stdp_type:', self.stdp_type)\n",
    "            print('self.penalty_input2e: ',  self.penalty_input2e)\n",
    "            print('self.penalty_efe: ', self.penalty_efe)\n",
    "            print('v_thres_exci: ', self.v_thres_exci) \n",
    "            print('v_reversal_e_exci: ', self.v_reversal_e_exci) \n",
    "            print('v_reversal_i_exci: ', self.v_reversal_i_exci) \n",
    "            print('v_rest_exci: ', self.v_rest_exci)\n",
    "            print('v_reset_exci: ', self.v_reset_exci)\n",
    "            print('refrac_time_exci: ', self.refrac_time_exci)\n",
    "            print('self.dW_e2e: ', self.dW_e2e)\n",
    "            print('self.w_sat_scale: ', self.w_sat_scale)\n",
    "            print('self.w_sat_shift: ', self.w_sat_shift)\n",
    "                \n",
    "    # common equations used for neuron, synapse and STDP groups\n",
    "    def set_equations(self, hyperParams):        \n",
    "        # neuron equation\n",
    "        self.eqs_neuron = '''\n",
    "            dv/dt = (ge*(Ee-v) + gi*(Ei-v)+ El - v)/tau_m + sigma_noise*xi*tau_m**-0.5: volt (unless refractory)\n",
    "            dge/dt = -ge/tau_ge : 1 (unless refractory)\n",
    "            dgi/dt = -gi/tau_gi : 1 (unless refractory)\n",
    "            dvt/dt = (v_thres-vt)/tau_adpt : volt (unless refractory) # adapt threshold\n",
    "            delta_vt: volt (constant)\n",
    "            vt_sat_scale: 1 (constant)\n",
    "            vt_sat_shift: 1 (constant)\n",
    "            tau_adpt: second (constant)\n",
    "            v_rest: volt (constant)\n",
    "            v_thres: volt (constant)\n",
    "            v_reset: volt (constant)\n",
    "            refrac_time: second (constant)\n",
    "            x: 1\n",
    "            y: 1\n",
    "            x_max: 1 (constant)\n",
    "            y_max: 1 (constant)\n",
    "            group: integer # which digit group does it belong to\n",
    "            label: integer # image label; can't be (shared) type for some reason\n",
    "            stimulus_idx : integer  # Index of the stimulus to show\n",
    "            stimulus_strength : 1  # Factor to scale up stimulus\n",
    "            tau_m: second (constant)\n",
    "            tau_ge: second (constant)\n",
    "            tau_gi: second (constant)\n",
    "            Ee: volt (constant)\n",
    "            Ei: volt (constant)\n",
    "            El: volt (constant)\n",
    "            sigma_noise: volt (constant) # random noise\n",
    "            rank: integer (constant) # rank in distributed training. Needed for S_e2e.connect() to avoid all-to-all connect in testing when test_option=add_more_neuron*\n",
    "        '''\n",
    "            \n",
    "        self.reset = '''\n",
    "            v = v_reset\n",
    "            vt += delta_vt*(0.5-0.5*tanh((-2*(vt-v_thres*(vt_sat_shift-0.5))/v_thres+1)/vt_sat_scale)) # gradually approach max \n",
    "        '''\n",
    "    \n",
    "        if self.debug==True:\n",
    "            print(' train with adaptive threshold ....')\n",
    "            print('eqs_neuron: ', self.eqs_neuron)\n",
    "\n",
    "        # STDP equations of different types\n",
    "        if self.stdp_type == 0: #synapse equation from Song, Miller and Abbott (2000) and Song and Abbott (2001)\n",
    "            if self.debug==True:\n",
    "                print(' using synapse equation from Song, Miller and Abbott (2000) and Song and Abbott (2001) ----- ')\n",
    "            \n",
    "            self.taupre = hyperParams['taupre']*brian2.ms\n",
    "            self.taupost = hyperParams['taupost']*brian2.ms\n",
    "            self.d_Apre = hyperParams['d_Apre']\n",
    "            self.d_Apost = -self.d_Apre * self.taupre / self.taupost * hyperParams['d_Apost_scale']\n",
    "            \n",
    "            self.eqs_syn = '''\n",
    "                w : 1\n",
    "                dApre/dt = -Apre / taupre : 1 (event-driven)\n",
    "                dApost/dt = -Apost / taupost : 1 (event-driven)\n",
    "                gmax: 1 (constant)\n",
    "                max_delay: second (constant)\n",
    "                max_dendritic_delay: second (constant)\n",
    "                normalized_ave: 1 (shared)\n",
    "                w_sat_scale: 1 (constant)\n",
    "                w_sat_shift: 1 (constant)\n",
    "            '''\n",
    "            \n",
    "            # don't add penalty to the pre_action, which trim unnecessary branches when label!=group because every pre-spike will reduce the weight\n",
    "            # However, when label==group, don't trim because post-neuron may not spike because of too high adaptive threshold. Just keep it as is.\n",
    "            self.STDP_pre_action = {'pre_nonplastic': 'ge += w',\n",
    "                                    'pre_plastic': ''' ge += w\n",
    "                                                       Apre += d_Apre\n",
    "                                                       w = clip(w + Apost, 0, gmax)'''}\n",
    "            self.STDP_post_action = '''Apost += d_Apost\n",
    "                                       w = clip(w + Apre, 0, gmax)'''\n",
    "            if self.task == 'train':\n",
    "                self.eqs_syn += '\\n penalty: 1 (shared)'\n",
    "                self.STDP_post_action = '''Apost += d_Apost\n",
    "                                           w = clip(w + Apre*(0.5-0.5*tanh((2*(w+gmax*(w_sat_shift-0.5))/gmax-1)/w_sat_scale))*(1- penalty*int(group_post!=label_post)), 0, gmax)'''\n",
    "        elif self.stdp_type ==1: \n",
    "            # minimum model of triplet equation for visual cortex, i.e. A2+ = A3- = 0, from Pfister and Gerstner, 2006 as implemented in Diehl and Cook (2015) and his github\n",
    "            # the actual parameter used in Diehl is different from the original paper. Can be further tuned if needed\n",
    "            if self.debug==True:    \n",
    "                print('---- using triplet equation from Pfister and Gerstner, 2006 as implemented in Diehl and Cook (2015) and his github ----- ')\n",
    "                \n",
    "            self.nu_pre_ee =  hyperParams['nu_pre_ee']      # A2- of the minimum triplet model\n",
    "            self.nu_post_ee = hyperParams['nu_post_ee']      # A3+ of the minimum triplet model\n",
    "            self.tc_pre_ee = hyperParams['tc_pre_ee']*brian2.ms\n",
    "            self.tc_post_1_ee = hyperParams['tc_post_1_ee']*brian2.ms\n",
    "            self.tc_post_2_ee = hyperParams['tc_post_2_ee']*brian2.ms\n",
    "                    \n",
    "            self.eqs_syn = '''\n",
    "                w : 1\n",
    "                post2before                            : 1\n",
    "                dpre/dt   =   -pre/(tc_pre_ee)         : 1 (event-driven)\n",
    "                dpost1/dt  = -post1/(tc_post_1_ee)     : 1 (event-driven)\n",
    "                dpost2/dt  = -post2/(tc_post_2_ee)     : 1 (event-driven)\n",
    "                gmax: 1 (constant) \n",
    "                max_delay: second (constant)\n",
    "                max_dendritic_delay: second (constant)\n",
    "                normalized_ave: 1 (shared)\n",
    "                w_sat_scale: 1 (constant)\n",
    "                w_sat_shift: 1 (constant)\n",
    "            '''\n",
    "            # don't add penalty to the pre_action, which trim unnecessary branches when label!=group because every pre-spike will reduce the weight\n",
    "            # However, when label==group, don't trim because post-neuron may not spike because of too high adaptive threshold. Just keep it as is. \n",
    "            self.STDP_pre_action = {'pre_nonplastic': 'ge += w',\n",
    "                                    'pre_plastic': '''ge += w \n",
    "                                                      pre = 1. \n",
    "                                                      w = clip(w - nu_pre_ee * post1, 0, gmax)'''}\n",
    "            self.STDP_post_action = '''post2before = post2 \n",
    "                                       w = clip(w + nu_post_ee * pre * post2before, 0, gmax) \n",
    "                                       post1 = 1. \n",
    "                                       post2 = 1.'''        \n",
    "            if self.task == 'train':\n",
    "                self.eqs_syn += '\\n penalty: 1 (shared)'\n",
    "                self.STDP_post_action = '''post2before = post2 \n",
    "                                           w = clip(w + nu_post_ee * pre * post2before *(0.5-0.5*tanh((2*(w+gmax*(w_sat_shift-0.5))/gmax-1)/w_sat_scale))*(1-penalty*int(group_post!=label_post)), 0, gmax) \n",
    "                                           post1 = 1. \n",
    "                                           post2 = 1.'''\n",
    "            \n",
    "    # add one set of regular neurons\n",
    "    def add_neurons(self, ih, n, name):\n",
    "        if self.test_option!=None and 'add_more_neuron' in self.test_option:\n",
    "            n = n*self.num_workers\n",
    "            if self.task != 'test' and self.task != 'advatk' and self.task != 'adv_make':\n",
    "                sys.exit(f'!!!! self.task={self.task}, need to be doing testing when with test_option: {self.test_option} !!!!')\n",
    "            if self.debug == True:\n",
    "                print(f' ---  add_neuron with n = {n} for test option: {self.test_option} -----')\n",
    "                \n",
    "        neurons = brian2.NeuronGroup(n, self.eqs_neuron, threshold='v>vt', reset=self.reset, refractory='refrac_time', method='euler', name=name)\n",
    "        \n",
    "        neuron_dir_path = os.path.join(self.dir_neuron_group, f'neuron_groups_exci_{ih}')    \n",
    "        if self.test_option == 'use_rank0_info':\n",
    "            rank = 0\n",
    "        else:\n",
    "            rank = self.rank\n",
    "            \n",
    "        if  find_file(f'rank{rank}.{input_param.data_format}', neuron_dir_path) is None: \n",
    "            neurons.ge = 0\n",
    "            neurons.gi = 0\n",
    "            neurons.v = 'v_rest + rand()*(v_thres - v_rest)'\n",
    "            neurons.tau_m = self.tau_membrane_exci[ih]\n",
    "            neurons.tau_ge = self.tau_ge[ih]\n",
    "            neurons.tau_gi = self.tau_gi[ih]\n",
    "            neurons.sigma_noise = self.sigma_noise\n",
    "            neurons.tau_adpt = self.tau_adpt[ih]\n",
    "            neurons.v_rest = self.v_rest_exci\n",
    "            neurons.v_thres = self.v_thres_exci\n",
    "            neurons.v_reset = self.v_reset_exci\n",
    "            neurons.refrac_time = self.refrac_time_exci\n",
    "            neurons.Ee = self.v_reversal_e_exci\n",
    "            neurons.Ei = self.v_reversal_i_exci\n",
    "            neurons.El = self.v_rest_exci\n",
    "            neurons.delta_vt = self.delta_vt[ih]\n",
    "            neurons.vt_sat_scale = self.vt_sat_scale\n",
    "            neurons.vt_sat_shift = self.vt_sat_shift\n",
    "            neurons.vt = self.v_thres_exci  # inital value of vt\n",
    "            neurons.v = self.v_rest_exci # inital value of v\n",
    "            \n",
    "            neurons.group, neurons.x, neurons.y, neurons.x_max, neurons.y_max = assign_element_of_array_to_random_groups(n, input_param.num_classes)\n",
    "            # now scale X/Y to match input layer size, in which case, the features of earlier layers and input layer are just\n",
    "            # directly added on top of each other, virtually forming a single layer with more features, as the input to the current hidden layer\n",
    "            seg_size = input_param.input_rows/self.sqrt_grp_size[ih] # divide input layer into segments of this size for each group\n",
    "            neurons.x = (neurons.x+0.5)*seg_size\n",
    "            neurons.y = (neurons.y+0.5)*seg_size\n",
    "            neurons.rank = rank\n",
    "        else:\n",
    "            if self.debug==True:\n",
    "                print('loading excitatory neurons: ', neuron_dir_path)\n",
    "            if self.test_option != None and 'add_more_neuron' in self.test_option:\n",
    "                list_dict = []\n",
    "                for ir in range(self.num_workers):\n",
    "                    list_dict.append(read_data(neuron_dir_path, ir))\n",
    "                if not None in list_dict:\n",
    "                    neuron_exci = concatenate_dict_arrays(list_dict)\n",
    "                else:\n",
    "                    neuron_exci = None\n",
    "                    sys.exit(f'!!!! neuron_exci at {neuron_dir_path} is None !!!!')\n",
    "            else:\n",
    "                neuron_exci = read_data(neuron_dir_path, rank)\n",
    "            \n",
    "            if self.debug==True and self.task!='train':\n",
    "                write_data(pd.DataFrame.from_dict(neuron_exci), neuron_dir_path, -1)\n",
    "            \n",
    "            # excitatory neuron information\n",
    "            if len(neuron_exci['ge']) >0: \n",
    "                neurons.ge[:] = neuron_exci['ge']\n",
    "                neurons.gi[:] = neuron_exci['gi']\n",
    "                neurons.v[:] = neuron_exci['v']*brian2.volt\n",
    "                neurons.tau_m[:] = neuron_exci['tau_m']*brian2.second\n",
    "                neurons.tau_ge[:] = neuron_exci['tau_ge']*brian2.second\n",
    "                neurons.tau_gi[:] = neuron_exci['tau_gi']*brian2.second\n",
    "                neurons.sigma_noise[:] = neuron_exci['sigma_noise']*brian2.volt\n",
    "                neurons.tau_adpt[:] = neuron_exci['tau_adpt']*brian2.second\n",
    "                neurons.v_rest[:] = neuron_exci['v_rest']*brian2.volt\n",
    "                neurons.v_thres[:] = neuron_exci['v_thres']*brian2.volt\n",
    "                neurons.v_reset[:] = neuron_exci['v_reset']*brian2.volt\n",
    "                neurons.refrac_time[:] = neuron_exci['refrac_time']*brian2.second\n",
    "                neurons.Ee[:] = neuron_exci['Ee']*brian2.volt\n",
    "                neurons.Ei[:] = neuron_exci['Ei']*brian2.volt\n",
    "                neurons.El[:] = neuron_exci['El']*brian2.volt\n",
    "                neurons.delta_vt[:] = neuron_exci['delta_vt']*brian2.volt\n",
    "                neurons.vt_sat_scale[:] = neuron_exci['vt_sat_scale']\n",
    "                neurons.vt_sat_shift[:] = neuron_exci['vt_sat_shift']\n",
    "                neurons.vt[:] = neuron_exci['vt']*brian2.volt \n",
    "                neurons.group[:] = neuron_exci['group']\n",
    "                neurons.x[:] = neuron_exci['x']\n",
    "                neurons.y[:] = neuron_exci['y']\n",
    "                neurons.x_max[:] = neuron_exci['x_max']\n",
    "                neurons.y_max[:] = neuron_exci['y_max']\n",
    "                neurons.rank[:] = neuron_exci['rank']\n",
    "            else:\n",
    "                sys.exit(f'!!!! neuron does not exist for rank {rank} and layer {ih}  !!!') \n",
    "            \n",
    "        return neurons\n",
    "\n",
    "    ##### the following are templates for multi-inheritance \n",
    "    def build_neurons(self):\n",
    "        pass\n",
    "    def build_synapses(self):\n",
    "        pass\n",
    "    def collect(self):\n",
    "        pass \n",
    "    def set_monitors(self):\n",
    "        pass\n",
    "    def save_neurons(self):\n",
    "        pass\n",
    "    def save_synapses(self):\n",
    "        pass\n",
    "    def set_syn_active_status(self):\n",
    "        pass\n",
    "    def save_neuron_coord(self):\n",
    "        pass\n",
    "    def plot(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_layer(spike): \n",
    "    def __init__(self, hyperParams):\n",
    "        super().__init__(hyperParams)\n",
    "        if self.debug==True:\n",
    "            print('--- initializing input_layer------')\n",
    "        \n",
    "    def build_neurons(self):\n",
    "        super().build_neurons()  # first parent of models, need this super() to call the same function in the 2nd parents of the model.\n",
    "        # input neuron with Poisson spikes #\n",
    "        if self.debug==True:\n",
    "            print(' building input neuron ...')\n",
    "        \n",
    "        self.input_neurons = brian2.NeuronGroup(input_param.Num_input_neuron, \n",
    "                                         '''x: 1\n",
    "                                            y: 1\n",
    "                                            x_max: 1 (constant)\n",
    "                                            y_max: 1 (constant)\n",
    "                                            switch_stimulus: boolean\n",
    "                                            correct_identification: boolean\n",
    "                                            higher_than_min_spike_rate: boolean\n",
    "                                            rate: Hz\n",
    "                                            label: integer\n",
    "                                            start_t : second  # Start time of the current trial\n",
    "                                            stimulus_idx : integer  # Index of the stimulus to show\n",
    "                                            stimulus_strength : 1  # Factor to scale up stimulus\n",
    "                                            repetitions : integer  # Number of times the stimulus has been presented\n",
    "                                            tot_repetitions : integer  # sum(repetitions)\n",
    "                                            ''', threshold='rand()<rate*dt', name='input_neurons',  \n",
    "                                            namespace = {'rows':input_param.input_rows, 'cols':input_param.input_cols})\n",
    "        \n",
    "        self.input_neurons.x = 'i%cols'  \n",
    "        self.input_neurons.y = 'rows - i//rows' # // is a floored division\n",
    "        self.input_neurons.x_max = 'rows-1'\n",
    "        self.input_neurons.y_max = 'cols-1'\n",
    "     \n",
    "    # build synapse\n",
    "    def build_synapses(self):\n",
    "        super().build_synapses()  # call the 2nd parent of the model\n",
    "        \n",
    "    # input and output neuron related containers are common to all models\n",
    "    def collect(self):\n",
    "        super().collect()\n",
    "        self.col.add(self.input_spikemon)\n",
    "        self.col.add(self.input_neurons)\n",
    "    \n",
    "    def set_monitors(self):\n",
    "        super().set_monitors()\n",
    "        if self.debug==True:\n",
    "            print('setup input layer monitors ...')\n",
    "        self.input_spikemon = brian2.SpikeMonitor(self.input_neurons, ['stimulus_idx', 'label', 'stimulus_strength', 'repetitions', 'tot_repetitions', \n",
    "                                                                       'correct_identification', 'higher_than_min_spike_rate'], name='input_spike_mon')\n",
    "        self.input_spikemon.active = self.activate_input_spikemon\n",
    "    \n",
    "    # plot input spikes\n",
    "    def plot(self):\n",
    "        super().plot()\n",
    "\n",
    "        fig0, axs0 = brian2.plt.subplots(1, 2, figsize=(12, 3))\n",
    "        axs0[0].scatter(self.input_neurons.x, self.input_neurons.y, c=self.input_spikemon.count)\n",
    "        axs0[0].set(xlabel='x', ylabel='y')\n",
    "        axs0[1].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.i, marker='.', linestyle='', markersize=0.7)\n",
    "        axs0[1].set(ylabel='nid', xlabel='Time (ms)')\n",
    "        \n",
    "        fig1, axs1 = brian2.plt.subplots(6, 1, sharex=True, figsize=(10, 15))\n",
    "        axs1[0].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.repetitions, color='C0')\n",
    "        axs1[0].set(ylabel='repetitions')\n",
    "        \n",
    "        axs1[1].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.tot_repetitions, color='C1')\n",
    "        axs1[1].set(ylabel='tot_repetitions')\n",
    "        \n",
    "        axs1[2].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.label, color='C2')\n",
    "        axs1[2].set(ylabel='input label')\n",
    "\n",
    "        axs1[3].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.stimulus_idx, color='C3')\n",
    "        axs1[3].set(ylabel='stimulus index')\n",
    "        twin_ax = axs1[3].twinx()\n",
    "        twin_ax.plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.stimulus_strength, color='C4')\n",
    "        twin_ax.set(ylabel='stimulus strength')\n",
    "        \n",
    "        axs1[4].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.correct_identification, color='C5')\n",
    "        axs1[4].set(ylabel='correct_identification')\n",
    "        \n",
    "        axs1[5].plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.higher_than_min_spike_rate, color='C6')\n",
    "        axs1[5].set(ylabel='higher_than_min_spike_rate')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hidden_layer(spike):\n",
    "    def __init__(self, hyperPar):\n",
    "        super().__init__(hyperPar) \n",
    "        if self.debug==True:\n",
    "            print('initializing hidden_layer------')\n",
    "    \n",
    "    # build input and output neurons, common for all models\n",
    "    def build_neurons(self):\n",
    "        super().build_neurons()  # 2nd parent of models, need this super() to call the same function in the 3rd parents of the model.\n",
    "        if self.debug==True:\n",
    "            print(' building neurons in hidden layers ...')\n",
    "        self.exci_neurons = []\n",
    "        for ih in range(self.N_hidden):\n",
    "            self.exci_neurons.append(super().add_neurons(ih, self.N_e[ih], 'exci_neurons'+str(ih)))\n",
    "        \n",
    "        # Used to keep track of the total number of spikes in all hidden layers\n",
    "        spike_counter_attribute = 'spike_counter : integer' +'\\n' # total number of spikes in all layers\n",
    "        for ig in range(input_param.num_classes):\n",
    "            spike_counter_attribute += 'spike_counter_grp'+str(ig)+' : integer' + '\\n'  # n_spikes in each group for all layers\n",
    "        for ih in range(self.N_hidden):\n",
    "            spike_counter_attribute += 'spike_counter_layer'+str(ih) + ' : integer' + '\\n' # evey layer has a spike counter\n",
    "                \n",
    "        if self.debug == True:\n",
    "            print('spike_counter_attribute --> \\n', spike_counter_attribute)\n",
    "            \n",
    "        self.spike_counter = brian2.NeuronGroup(1, spike_counter_attribute, name='spike_counter')\n",
    "    \n",
    "    # save the neurons. \n",
    "    def save_neurons(self):\n",
    "        super().save_neurons()\n",
    "        if self.debug==True:\n",
    "            print(' saving the neuron information in: ', self.dir_neuron_group)\n",
    "\n",
    "        for ih in range(self.N_hidden):\n",
    "            df = pd.DataFrame({'ge': self.exci_neurons[ih].ge[:],\n",
    "                               'gi': self.exci_neurons[ih].gi[:],\n",
    "                               'v': self.exci_neurons[ih].v[:],\n",
    "                               'tau_m': self.exci_neurons[ih].tau_m[:],\n",
    "                               'tau_ge': self.exci_neurons[ih].tau_ge[:],\n",
    "                               'tau_gi': self.exci_neurons[ih].tau_gi[:],\n",
    "                               'sigma_noise': self.exci_neurons[ih].sigma_noise[:],\n",
    "                               'tau_adpt': self.exci_neurons[ih].tau_adpt[:],\n",
    "                               'v_rest': self.exci_neurons[ih].v_rest[:],\n",
    "                               'v_thres': self.exci_neurons[ih].v_thres[:],\n",
    "                               'v_reset': self.exci_neurons[ih].v_reset[:],\n",
    "                               'refrac_time': self.exci_neurons[ih].refrac_time[:],\n",
    "                               'Ee': self.exci_neurons[ih].Ee[:],\n",
    "                               'Ei': self.exci_neurons[ih].Ei[:],\n",
    "                               'El': self.exci_neurons[ih].El[:],\n",
    "                               'delta_vt': self.exci_neurons[ih].delta_vt[:],\n",
    "                               'vt_sat_scale': self.exci_neurons[ih].vt_sat_scale[:],\n",
    "                               'vt_sat_shift': self.exci_neurons[ih].vt_sat_shift[:],\n",
    "                               'vt': self.exci_neurons[ih].vt[:],  # inital value of vt\n",
    "                               'v': self.exci_neurons[ih].v[:], # inital value of v\n",
    "                               'group': self.exci_neurons[ih].group[:],\n",
    "                               'x': self.exci_neurons[ih].x[:],\n",
    "                               'y': self.exci_neurons[ih].y[:],\n",
    "                               'x_max': self.exci_neurons[ih].x_max[:],\n",
    "                               'y_max': self.exci_neurons[ih].y_max[:],\n",
    "                               'rank': self.exci_neurons[ih].rank[:]})\n",
    "            \n",
    "            write_data(df, os.path.join(self.dir_neuron_group, f'neuron_groups_exci_{ih}'), self.rank)\n",
    "                        \n",
    "    # build synapse\n",
    "    def build_synapses(self):\n",
    "        super().build_synapses() \n",
    "        \n",
    "        # dummy synapses to keep track of the total number of spikes in all hidden layers\n",
    "        self.counter_synapse=[]\n",
    "        for ih in range(self.N_hidden):\n",
    "            counter_syn_action = 'spike_counter += 1' + '\\n'\n",
    "            counter_syn_action +='spike_counter_layer' + str(ih) + '+=1' + '\\n'\n",
    "            for ig in range(input_param.num_classes): # n_spikes in each group for all layers\n",
    "                counter_syn_action += 'spike_counter_grp'+str(ig) + '+=1*int('+str(ig)+'==group_pre)' +'\\n'\n",
    "            \n",
    "            # when n_spikes<n_spike_sample_min, delta_vt = -fixed_delta_vt. This is better than delta_vt=0 which can't lower the threshold to\n",
    "            if self.task == 'train':\n",
    "                counter_syn_action +='delta_vt_pre = fixed_delta_vt*int(spike_counter_layer' + str(ih) + '>=n_spike_sample_min) - fixed_delta_vt*int(spike_counter_layer' + str(ih) + '<n_spike_sample_min)' +'\\n'\n",
    "            \n",
    "            if self.debug==True:\n",
    "                print('counter_syn_action-->\\n', counter_syn_action)\n",
    "            \n",
    "            self.counter_synapse.append(brian2.Synapses(self.exci_neurons[ih], self.spike_counter,  on_pre=counter_syn_action, name='counter_synapse'+str(ih), \n",
    "                                                       namespace={'n_spike_sample_min':input_param.n_spike_sample_min, 'fixed_delta_vt':self.delta_vt[ih]}))\n",
    "            self.counter_synapse[ih].connect()\n",
    "                        \n",
    "        # syn within individual hidden layer\n",
    "        if self.task!='train':\n",
    "            self.S_e2e = [None]*self.N_hidden # excitatory to excitatory between different group w/o STDP\n",
    "            for ih in range(self.N_hidden):\n",
    "                self.S_e2e[ih] = brian2.Synapses(self.exci_neurons[ih], self.exci_neurons[ih], 'dW_e2e: 1(constant)', \n",
    "                                                            on_pre='gi += dW_e2e', name='s_e2e'+str(ih))\n",
    "                self.S_e2e[ih].connect(condition='group_pre!=group_post and x_pre==x_post and y_pre==y_post and rank_pre==rank_post')\n",
    "                self.S_e2e[ih].dW_e2e = self.dW_e2e[ih]\n",
    "            \n",
    "    # save the synapses. \n",
    "    def save_synapses(self):\n",
    "        super().save_synapses()\n",
    "        if self.debug==True and self.task!='train': \n",
    "            for ih in range(self.N_hidden):\n",
    "                df = pd.DataFrame({'i': self.S_e2e[ih].i[:], 'j': self.S_e2e[ih].j[:]})\n",
    "                write_data(df, os.path.join(self.dir_syn_in, 'S_e2e_hid'+str(ih)), self.rank)\n",
    "        \n",
    "    # input and output neuron related containers are common to all models        \n",
    "    def set_monitors(self):\n",
    "        super().set_monitors()\n",
    "        if self.debug==True:\n",
    "            print('setup hidden layer monitors...')\n",
    "        self.exci_statemon =[]\n",
    "        self.exci_spikemon = []\n",
    "        record_list = [ih for ih in range(0, 9)]\n",
    "        for ih in range(self.N_hidden):\n",
    "            self.exci_statemon.append(brian2.StateMonitor(self.exci_neurons[ih], True, record=record_list)) # for the case of N_neuron, e.g. [400, 6]\n",
    "            self.exci_statemon[ih].active = self.debug\n",
    "            \n",
    "            self.exci_spikemon.append(brian2.SpikeMonitor(self.exci_neurons[ih], ['label', 'group', 'stimulus_idx', 'stimulus_strength'], name='exci_spikemon'+str(ih)))\n",
    "            self.exci_spikemon[ih].active = True\n",
    "        \n",
    "    # input and output neuron related containers are common to all models\n",
    "    def collect(self):\n",
    "        super().collect()\n",
    "        self.col.add(self.exci_neurons)\n",
    "        self.col.add(self.exci_spikemon)\n",
    "        self.col.add(self.exci_statemon)\n",
    "        self.col.add(self.spike_counter)\n",
    "        self.col.add(self.counter_synapse)\n",
    "        if self.task != 'train':\n",
    "            self.col.add(self.S_e2e)\n",
    "        \n",
    "    # save spikes from a certain spikemon\n",
    "    def count_last_hlayer_spikes_from_spikemon(self):\n",
    "        count = [0]*input_param.num_classes #spike counts in each digit\n",
    "        for i in range(len(self.exci_spikemon[self.N_hidden-1].all_values()['group'])): # loop over each neuron in the last h-layer\n",
    "            for g in self.exci_spikemon[self.N_hidden-1].all_values()['group'][i]:\n",
    "                count[g] += 1\n",
    "        \n",
    "        if self.debug==True:\n",
    "            print('number of input spikes : ', self.input_spikemon.num_spikes)\n",
    "            for ih in range(self.N_hidden):            \n",
    "                print('number of exci spikes for layer'+str(ih)+': ', self.exci_spikemon[ih].num_spikes)\n",
    "        \n",
    "        return count\n",
    "                            \n",
    "    # set active = True/False for pre and post in syn for training and testing\n",
    "    def set_syn_active_status(self):\n",
    "        super().set_syn_active_status()\n",
    "                                \n",
    "    # what to plot. \n",
    "    def what_to_plot(self, sub, state_mon):\n",
    "            sub[0].plot(state_mon.t/brian2.ms, state_mon.v.T)\n",
    "            sub[0].set(xlabel='Time (s)', ylabel='v(mV)')\n",
    "            sub[0].set_xlim([0, 2000])\n",
    "            sub[0].legend(loc=\"upper left\")\n",
    "            \n",
    "            sub[1].plot(state_mon.t/brian2.ms, state_mon.ge.T)            \n",
    "            sub[1].set(xlabel='Time (s)', ylabel='ge')\n",
    "            sub[1].set_xlim([0, 2000])\n",
    "            sub[1].legend(loc=\"upper left\")\n",
    "            \n",
    "            sub[2].plot(state_mon.t/brian2.ms, state_mon.delta_vt.T)\n",
    "            sub[2].set(xlabel='Time (s)', ylabel='delta_vt')\n",
    "            sub[2].legend(loc=\"upper left\")\n",
    "            \n",
    "            sub[3].plot(state_mon.t/brian2.ms, state_mon.vt.T)\n",
    "            sub[3].set(xlabel='Time (s)', ylabel='vt')\n",
    "            sub[3].legend(loc=\"upper left\")\n",
    "\n",
    "        \n",
    "    # plot the result, slow and mostly for debugging purpose\n",
    "    def plot(self):\n",
    "        super().plot()\n",
    "        # i vs. t for input layer and all hidden layers\n",
    "        brian2.plt.figure(figsize=(15, 10))\n",
    "        brian2.plot(self.input_spikemon.t/brian2.ms, self.input_spikemon.i, label='input layer', marker='.', linestyle='', markersize=1)\n",
    "        for ih in range(self.N_hidden):\n",
    "            brian2.plot(self.exci_spikemon[ih].t/brian2.ms, self.exci_spikemon[ih].i, label='layer'+str(ih), marker='o', linestyle='', fillstyle='none', markersize=5)\n",
    "        brian2.plt.legend(loc=\"upper left\")\n",
    "        #brian2.plt.xlim(0, 2000)\n",
    "        \n",
    "        if self.task == 'train':\n",
    "            brian2.plt.figure(figsize=(5, 5))\n",
    "            brian2.plot(self.exci_spikemon[ih].t/brian2.ms, self.exci_spikemon[ih].label, label='input label in exci_neuron', color='C1')\n",
    "            brian2.plt.legend(loc=\"upper left\")\n",
    "            \n",
    "        # n_cycle and n_spikes vs. t\n",
    "        brian2.plt.figure(figsize=(15, 15))\n",
    "        #brian2.plt.xlim(0, 2000)\n",
    "        for ih in range(self.N_hidden):\n",
    "            brian2.plot(self.exci_statemon[ih].t/brian2.ms, self.exci_statemon[ih].v.T*(-100)) # x-100 to make it visible\n",
    "            brian2.plot(self.exci_statemon[ih].t/brian2.ms, self.exci_statemon[ih].ge.T)\n",
    "        brian2.plt.xlabel('Time (s)')\n",
    "        brian2.plt.ylabel('n_cycle/n_spikes/v/ge')\n",
    "        brian2.plt.legend(loc=\"upper left\")\n",
    "            \n",
    "        # V vs. t & ge vs. t for hidden layer \n",
    "        fig, axs = brian2.plt.subplots(self.N_hidden, 4, figsize=(12,3))\n",
    "        if self.N_hidden ==1:\n",
    "            self.what_to_plot(axs, self.exci_statemon[0])\n",
    "        else:\n",
    "            for ih in range(self.N_hidden):\n",
    "                self.what_to_plot(axs[ih], self.exci_statemon[ih])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
